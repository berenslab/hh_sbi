{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6639c63-a896-44cc-8e58-c58a3624a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# import saver utilities\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee96c2c6-7ab7-40cd-acf9-0dda49de4dac",
   "metadata": {},
   "source": [
    "## Load observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6447907b-7675-4e66-9acd-f0063aa142c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All 25 degree Celcius mouse motor cortex (M1) electrophysiological data, preprocessed\n",
    "M1_25degree = pickle.load(open('pickles/M1_features.pickle', 'rb'))\n",
    "ephys_features = M1_25degree['X_o'].columns\n",
    "Xo = M1_25degree['X_o'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e7f214-48ef-442e-9a66-2c310bc67681",
   "metadata": {},
   "source": [
    "We decide to kick out observed ephys cells with low quality rna already from the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "403d9117-834a-4934-88c9-dc9808e8b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop = pd.read_csv('../data/m1_patchseq_meta_data.csv', sep = '\\t')\n",
    "prop = prop.rename(columns = {'Targeted layer': 'Layer'})\n",
    "prop = prop[['Cell', 'Layer', 'Cre', 'RNA type']]\n",
    "prop = prop.set_index('Cell')\n",
    "prop=prop.reindex(Xo.index)\n",
    "no_low_qual=np.array(list(map(str,prop['RNA type'].values)))!='nan'\n",
    "prop=prop.loc[no_low_qual,:]\n",
    "Xo = Xo.loc[no_low_qual,:]\n",
    "celltypes=prop['RNA type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d57dd9a-acbb-4c79-a845-5cd0fb69e0ef",
   "metadata": {},
   "source": [
    "## Load 10 random samples and highest posterior samples for each observed cell and every amortized posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78cbd361-9270-4d6f-8cc8-94cbdea8b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_schedules=['0', '1', '2a', '2b', '2c', '2d', '2e', '3', '4']\n",
    "model_param_names = np.array(['C', r'$R_{input}$', r'$\\tau$', r'$g_{Nat}$', r'$g_{Na}$', r'$g_{Kd}$', r'$g_{M}$',\n",
    "                         r'$g_{Kv31}$', r'$g_{L}$', r'$E_{leak}$', r'$\\tau_{max}$', 'VT', 'rate_to_SS_factor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99833528-8307-4f8e-862d-27b9a71d64a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('save_model_parameters/across_training_schedules.pickle', 'rb') as f:\n",
    "        THETAS = pickle.load(f)\n",
    "highest_posterior_samples=np.concatenate(\n",
    "    [[THETAS[tr_schedule]['highest posterior samples'][cell] for cell in Xo.index] for tr_schedule in THETAS]\n",
    ")\n",
    "posterior_samples_10_random=np.concatenate(\n",
    "    [[THETAS[tr_schedule]['10 random samples'][cell].numpy() for cell in Xo.index] for tr_schedule in THETAS]\n",
    ").reshape((Xo.shape[0]*len(training_schedules)*10,len(model_param_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceaab61-abce-4919-8c49-8ff7c2b38cb8",
   "metadata": {},
   "source": [
    "#### Let's get their summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f12fe92-ce1c-4b5f-a356-64e9328aded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulator import EphysModel\n",
    "\n",
    "M1_model=EphysModel(name='M1',\n",
    "                   T=25.0,\n",
    "                   E_Na=69.0,\n",
    "                   E_K=-98.4,\n",
    "                   E_Ca=127.2,\n",
    "                   start=100,\n",
    "                   end=700,\n",
    "                   dt=0.04,\n",
    "                   label_params=model_param_names,\n",
    "                   ephys_features=ephys_features,\n",
    "                   n_processes=40,\n",
    "                   noise_factor=10,\n",
    "                   use_pathos=True,\n",
    "                   chunk_size=10000,\n",
    "                   save_chunks=True,\n",
    "                   verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "744c6a0d-327f-4777-a24a-519f640686c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks:\n",
      ".\n",
      "Training set of parameters and summary statistics has been made:\n",
      "parameters shape:  torch.Size([8595, 13])\n",
      "summary statistics shape:  torch.Size([8595, 23])\n",
      "Highest posterior sample simulations done.\n"
     ]
    }
   ],
   "source": [
    "M1_model.sim(torch.as_tensor(highest_posterior_samples, dtype=torch.float32))\n",
    "np.savez('./save_sims/highest_posterior_samples_summ_stats.npz',\n",
    "     stats=M1_model.stats.numpy()\n",
    "    )\n",
    "print('Highest posterior sample simulations done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7bede196-5b22-4280-ba7b-80d4f9c0153c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks:\n",
      ".........\n",
      "Training set of parameters and summary statistics has been made:\n",
      "parameters shape:  torch.Size([85950, 13])\n",
      "summary statistics shape:  torch.Size([85950, 23])\n",
      "10 random posterior sample simulations done.\n"
     ]
    }
   ],
   "source": [
    "M1_model.sim(torch.as_tensor(posterior_samples_10_random, dtype=torch.float32))\n",
    "np.savez('./save_sims/posterior_samples_10_random_summ_stats.npz',\n",
    "     stats=M1_model.stats.numpy()\n",
    "    )\n",
    "print('10 random posterior sample simulations done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7036248-8237-435a-a352-a6ea833428ee",
   "metadata": {},
   "source": [
    "## Report performance of each training schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ffebe5b7-6f40-4385-8e1f-6988d1e611c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_post_stats=np.load('./save_sims/highest_posterior_samples_summ_stats.npz')['stats']\n",
    "highest_post_stats_nans=np.isnan(highest_post_stats.mean(axis=1))\n",
    "highest_post_stats_nans_reshaped=highest_post_stats_nans.reshape((len(training_schedules), Xo.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "22256019-8305-459e-9a6b-564e83fd2cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfomance for each amortized posterior or each training schedule regarding drawing highest posterior samples: \n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training schedule 0:  142 out of 955 failed or 14.87 %. \n",
      "On simulations that were succesful we are 5.89 +/- 3.26 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n",
      "\n",
      "Training schedule 1:  116 out of 955 failed or 12.15 %. \n",
      "On simulations that were succesful we are 5.41 +/- 3.15 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n",
      "\n",
      "Training schedule 2a:  95 out of 955 failed or 9.95 %. \n",
      "On simulations that were succesful we are 5.30 +/- 3.15 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n",
      "\n",
      "Training schedule 2b:  42 out of 955 failed or 4.40 %. \n",
      "On simulations that were succesful we are 4.77 +/- 2.88 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n",
      "\n",
      "Training schedule 2c:  35 out of 955 failed or 3.66 %. \n",
      "On simulations that were succesful we are 4.52 +/- 2.89 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n",
      "\n",
      "Training schedule 2d:  32 out of 955 failed or 3.35 %. \n",
      "On simulations that were succesful we are 4.69 +/- 3.02 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n",
      "\n",
      "Training schedule 2e:  20 out of 955 failed or 2.09 %. \n",
      "On simulations that were succesful we are 3.92 +/- 2.27 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n",
      "\n",
      "Training schedule 3:  58 out of 955 failed or 6.07 %. \n",
      "On simulations that were succesful we are 4.93 +/- 2.75 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n",
      "\n",
      "Training schedule 4:  74 out of 955 failed or 7.75 %. \n",
      "On simulations that were succesful we are 4.62 +/- 3.12 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n"
     ]
    }
   ],
   "source": [
    "Xo_repeated=np.concatenate([Xo.values[:,:-4]]*len(training_schedules), axis=0)\n",
    "Xo_mean=Xo.values[:,:-4].mean(axis=0)\n",
    "Xo_std=Xo.values[:,:-4].std(axis=0)\n",
    "\n",
    "print('Perfomance for each amortized posterior or each training schedule regarding drawing highest posterior samples: ')\n",
    "print('---------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "for i, tr_schedule in enumerate(training_schedules):\n",
    "    score=np.mean(\n",
    "        np.sqrt(\n",
    "            np.sum(\n",
    "                (\n",
    "                    (highest_post_stats[Xo.shape[0]*i:Xo.shape[0]*(i+1),:][~highest_post_stats_nans[Xo.shape[0]*i:Xo.shape[0]*(i+1)],:]-Xo_mean)/Xo_std-\\\n",
    "                    (Xo_repeated[Xo.shape[0]*i:Xo.shape[0]*(i+1),:][~highest_post_stats_nans[Xo.shape[0]*i:Xo.shape[0]*(i+1)],:]-Xo_mean)/Xo_std\n",
    "                )**2,axis=1\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    score_sd=np.std(\n",
    "        np.sqrt(\n",
    "            np.sum(\n",
    "                (\n",
    "                    (highest_post_stats[Xo.shape[0]*i:Xo.shape[0]*(i+1),:][~highest_post_stats_nans[Xo.shape[0]*i:Xo.shape[0]*(i+1)],:]-Xo_mean)/Xo_std-\\\n",
    "                    (Xo_repeated[Xo.shape[0]*i:Xo.shape[0]*(i+1),:][~highest_post_stats_nans[Xo.shape[0]*i:Xo.shape[0]*(i+1)],:]-Xo_mean)/Xo_std\n",
    "                )**2,axis=1\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    print('\\nTraining schedule {}: '.format(tr_schedule), sum(highest_post_stats_nans_reshaped[i,:]), 'out of', Xo.shape[0],\n",
    "          'failed or {:.2f} %.'.format(sum(highest_post_stats_nans_reshaped[i,:])/(Xo.shape[0])*100),\n",
    "          '\\nOn simulations that were succesful we are {:.2f} +/- {:.2f} (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.'.format(score, score_sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "18460ac6-9c5b-4571-bfe5-0cc98e1dd377",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_prior_stats=np.load('./save_sims/best_1000_Euclidean_sims.npz')['stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "31070f46-f78a-433d-bcfb-4f088be6bdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W.r.t. the prior: \n",
      "----------------- \n",
      "0 out of 955 failed or 0.00 %. \n",
      "On simulations that were succesful we are 2.63 +/- 0.81 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n"
     ]
    }
   ],
   "source": [
    "best_prior_stats=np.load('./save_sims/best_1000_Euclidean_sims.npz')['stats'][::1000,:]\n",
    "best_prior_stats_nans=np.isnan(best_prior_stats.sum(axis=1))\n",
    "Xo_values=Xo.values[:,:-4]\n",
    "Xo_mean=Xo.values[:,:-4].mean(axis=0)\n",
    "Xo_std=Xo.values[:,:-4].std(axis=0)\n",
    "print('W.r.t. the prior: ')\n",
    "print('----------------- ')\n",
    "score=np.mean(\n",
    "    np.sqrt(\n",
    "        np.sum(\n",
    "            (\n",
    "                (best_prior_stats[~best_prior_stats_nans,:]-Xo_mean)/Xo_std-\\\n",
    "                (Xo_values[~best_prior_stats_nans,:]-Xo_mean)/Xo_std\n",
    "            )**2,axis=1\n",
    "        )\n",
    "    )\n",
    ")\n",
    "score_sd=np.std(\n",
    "    np.sqrt(\n",
    "        np.sum(\n",
    "            (\n",
    "                (best_prior_stats[~best_prior_stats_nans,:]-Xo_mean)/Xo_std-\\\n",
    "                (Xo_values[~best_prior_stats_nans,:]-Xo_mean)/Xo_std\n",
    "            )**2,axis=1\n",
    "        )\n",
    "    )\n",
    ")\n",
    "print(sum(best_prior_stats_nans), 'out of', Xo.shape[0],\n",
    "      'failed or {:.2f} %.'.format(sum(best_prior_stats_nans)/(Xo.shape[0])*100),\n",
    "      '\\nOn simulations that were succesful we are {:.2f} +/- {:.2f} (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.'.format(score, score_sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0307b598-cd77-41c8-bcb7-15e3adc4c17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_samples_10_random_stats=np.load('./save_sims/posterior_samples_10_random_summ_stats.npz')['stats']\n",
    "post_samples_10_random_stats_nans=np.isnan(post_samples_10_random_stats.mean(axis=1))\n",
    "post_samples_10_random_stats_nans_reshaped=post_samples_10_random_stats_nans.reshape((len(training_schedules), Xo.shape[0]*10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e3f909f3-79dd-4798-99bd-b9b3b2ba51b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfomance for each amortized posterior or each training schedule regarding drawing 10 random posterior samples: \n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training schedule 0:  1944 out of 9550 failed or 20.36 %. \n",
      "On simulations that were succesful we are 6.65 +/- 3.38 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n",
      "\n",
      "Training schedule 1:  1584 out of 9550 failed or 16.59 %. \n",
      "On simulations that were succesful we are 5.63 +/- 3.49 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n",
      "\n",
      "Training schedule 2a:  1450 out of 9550 failed or 15.18 %. \n",
      "On simulations that were succesful we are 5.70 +/- 3.29 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n",
      "\n",
      "Training schedule 2b:  680 out of 9550 failed or 7.12 %. \n",
      "On simulations that were succesful we are 5.28 +/- 3.09 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n",
      "\n",
      "Training schedule 2c:  588 out of 9550 failed or 6.16 %. \n",
      "On simulations that were succesful we are 5.18 +/- 3.04 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n",
      "\n",
      "Training schedule 2d:  702 out of 9550 failed or 7.35 %. \n",
      "On simulations that were succesful we are 5.18 +/- 3.04 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n",
      "\n",
      "Training schedule 2e:  865 out of 9550 failed or 9.06 %. \n",
      "On simulations that were succesful we are 5.29 +/- 2.60 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n",
      "\n",
      "Training schedule 3:  923 out of 9550 failed or 9.66 %. \n",
      "On simulations that were succesful we are 6.21 +/- 2.84 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n",
      "\n",
      "Training schedule 4:  1059 out of 9550 failed or 11.09 %. \n",
      "On simulations that were succesful we are 5.38 +/- 3.22 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n"
     ]
    }
   ],
   "source": [
    "Xo_repeated=np.repeat(Xo.values[:,:-4], 10, axis=0)\n",
    "Xo_repeated=np.concatenate([Xo_repeated]*len(training_schedules), axis=0)\n",
    "Xo_mean=Xo.values[:,:-4].mean(axis=0)\n",
    "Xo_std=Xo.values[:,:-4].std(axis=0)\n",
    "\n",
    "print('Perfomance for each amortized posterior or each training schedule regarding drawing 10 random posterior samples: ')\n",
    "print('-----------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "for i, tr_schedule in enumerate(training_schedules):\n",
    "    score=np.mean(\n",
    "        np.sqrt(\n",
    "            np.sum(\n",
    "                (\n",
    "                    (post_samples_10_random_stats[Xo.shape[0]*10*i:Xo.shape[0]*10*(i+1),:][~post_samples_10_random_stats_nans[Xo.shape[0]*10*i:Xo.shape[0]*10*(i+1)],:]-Xo_mean)/Xo_std-\\\n",
    "                    (Xo_repeated[Xo.shape[0]*10*i:Xo.shape[0]*10*(i+1),:][~post_samples_10_random_stats_nans[Xo.shape[0]*10*i:Xo.shape[0]*10*(i+1)],:]-Xo_mean)/Xo_std\n",
    "                )**2,axis=1\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    score_sd=np.std(\n",
    "        np.sqrt(\n",
    "            np.sum(\n",
    "                (\n",
    "                    (post_samples_10_random_stats[Xo.shape[0]*10*i:Xo.shape[0]*10*(i+1),:][~post_samples_10_random_stats_nans[Xo.shape[0]*10*i:Xo.shape[0]*10*(i+1)],:]-Xo_mean)/Xo_std-\\\n",
    "                    (Xo_repeated[Xo.shape[0]*10*i:Xo.shape[0]*10*(i+1),:][~post_samples_10_random_stats_nans[Xo.shape[0]*10*i:Xo.shape[0]*10*(i+1)],:]-Xo_mean)/Xo_std\n",
    "                )**2,axis=1\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    print('\\nTraining schedule {}: '.format(tr_schedule), sum(post_samples_10_random_stats_nans_reshaped[i,:]), 'out of', Xo.shape[0]*10,\n",
    "          'failed or {:.2f} %.'.format(sum(post_samples_10_random_stats_nans_reshaped[i,:])/(Xo.shape[0]*10)*100),\n",
    "          '\\nOn simulations that were succesful we are {:.2f} +/- {:.2f} (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.'.format(score, score_sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8a9b4764-8fd2-4c8c-9f35-7bcfa8c1cac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W.r.t. the prior: \n",
      "----------------- \n",
      "5024 out of 9550 failed or 52.61 %. \n",
      "On simulations that were succesful we are 11.86 +/- 3.32 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n"
     ]
    }
   ],
   "source": [
    "prior_stats=np.load('./save_sims/M1_chunks/full_batch.npz')['stats']\n",
    "prior_10_random_stats=prior_stats[np.random.randint(0,prior_stats.shape[0],Xo.shape[0]*10),:]\n",
    "prior_10_random_stats_nans=np.isnan(prior_10_random_stats.sum(axis=1))\n",
    "Xo_repeated=np.repeat(Xo.values[:,:-4], 10, axis=0)\n",
    "Xo_mean=Xo.values[:,:-4].mean(axis=0)\n",
    "Xo_std=Xo.values[:,:-4].std(axis=0)\n",
    "\n",
    "print('W.r.t. the prior: ')\n",
    "print('----------------- ')\n",
    "score=np.mean(\n",
    "    np.sqrt(\n",
    "        np.sum(\n",
    "            (\n",
    "                (prior_10_random_stats[~prior_10_random_stats_nans,:]-Xo_mean)/Xo_std-\\\n",
    "                (Xo_repeated[~prior_10_random_stats_nans,:]-Xo_mean)/Xo_std\n",
    "            )**2,axis=1\n",
    "        )\n",
    "    )\n",
    ")\n",
    "score_sd=np.std(\n",
    "    np.sqrt(\n",
    "        np.sum(\n",
    "            (\n",
    "                (prior_10_random_stats[~prior_10_random_stats_nans,:]-Xo_mean)/Xo_std-\\\n",
    "                (Xo_repeated[~prior_10_random_stats_nans,:]-Xo_mean)/Xo_std\n",
    "            )**2,axis=1\n",
    "        )\n",
    "    )\n",
    ")\n",
    "print(sum(prior_10_random_stats_nans), 'out of', Xo.shape[0]*10,\n",
    "      'failed or {:.2f} %.'.format(sum(prior_10_random_stats_nans)/(Xo.shape[0]*10)*100),\n",
    "      '\\nOn simulations that were succesful we are {:.2f} +/- {:.2f} (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.'.format(score, score_sd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d96f6b-8cff-47c8-b275-3ab3b2f2ea2f",
   "metadata": {},
   "source": [
    "We can pick our favourite training schedule and generate more samples with their evaluations. We will use this when we train the next neural network predicting model parameter distributions based on gene expression levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b2eaddd1-afa9-4064-b177-4a66d939aea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_tr_schedule='2c'\n",
    "with open('./save_posteriors/training_schedule_{}.pickle'.format(fav_tr_schedule), 'rb') as f:\n",
    "    posterior = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c9962642-3462-4137-a096-3377a513697e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "index=0\n",
    "feature_list=range(23)\n",
    "fav_training_schedule={'samples':{}, 'evaluations':{}}\n",
    "for i in range(index, Xo.shape[0]):\n",
    "    xo=Xo.iloc[i,:].values\n",
    "    cell_name=Xo.index[i]\n",
    "    print('.', end='')\n",
    "\n",
    "    # sampling 1000 from the posterior\n",
    "    samples=posterior.sample(\n",
    "        (1000,),\n",
    "        x=torch.as_tensor(xo[feature_list], dtype=float),\n",
    "        show_progress_bars=False\n",
    "    )\n",
    "    evaluations=posterior.log_prob(\n",
    "        samples,\n",
    "        x=torch.as_tensor(xo[feature_list], dtype=float)\n",
    "    )\n",
    "    fav_training_schedule['samples'].update({cell_name:samples.numpy()})\n",
    "    fav_training_schedule['evaluations'].update({cell_name:evaluations.numpy()})\n",
    "    \n",
    "with open('save_model_parameters/favourite_training_schedule.pickle', 'wb') as f:\n",
    "    pickle.dump(fav_training_schedule, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
