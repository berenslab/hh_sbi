{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6639c63-a896-44cc-8e58-c58a3624a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# import saver utilities\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee96c2c6-7ab7-40cd-acf9-0dda49de4dac",
   "metadata": {},
   "source": [
    "## Load observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6447907b-7675-4e66-9acd-f0063aa142c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All 25 degree Celcius mouse motor cortex (M1) electrophysiological data, preprocessed\n",
    "M1_25degree = pickle.load(open('pickles/M1_features.pickle', 'rb'))\n",
    "ephys_features = M1_25degree['X_o'].columns\n",
    "Xo = M1_25degree['X_o'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e7f214-48ef-442e-9a66-2c310bc67681",
   "metadata": {},
   "source": [
    "We decide to kick out observed ephys cells with low quality rna already from the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "403d9117-834a-4934-88c9-dc9808e8b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop = pd.read_csv('../data/m1_patchseq_meta_data.csv', sep = '\\t')\n",
    "prop = prop.rename(columns = {'Targeted layer': 'Layer'})\n",
    "prop = prop[['Cell', 'Layer', 'Cre', 'RNA type']]\n",
    "prop = prop.set_index('Cell')\n",
    "prop=prop.reindex(Xo.index)\n",
    "no_low_qual=np.array(list(map(str,prop['RNA type'].values)))!='nan'\n",
    "prop=prop.loc[no_low_qual,:]\n",
    "Xo = Xo.loc[no_low_qual,:]\n",
    "Xo = Xo.iloc[:,:-4]\n",
    "celltypes=prop['RNA type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e30ff2ee-6457-4606-9c27-28cdee2c67e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xo_mean=Xo.values.mean(axis=0)\n",
    "Xo_std=Xo.values.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4d3ffb1-12dc-4c09-afbd-b9db76287686",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param_names = np.array(['C', r'$R_{input}$', r'$\\tau$', r'$g_{Nat}$', r'$g_{Na}$', r'$g_{Kd}$', r'$g_{M}$',\n",
    "                         r'$g_{Kv31}$', r'$g_{L}$', r'$E_{leak}$', r'$\\tau_{max}$', 'VT', 'rate_to_SS_factor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d57dd9a-acbb-4c79-a845-5cd0fb69e0ef",
   "metadata": {},
   "source": [
    "## Report performance for each training schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ded654a-ff7c-48c2-a96c-6212b096d161",
   "metadata": {},
   "source": [
    "#### Pick your training schedule (0, 1, 2a, 2b, 2c, 2d, 2e, 3 or 4). 2d corresponds to NPE+. 0 to NPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea018856-2973-4d91-a903-171aaefd507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_schedule='2d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99833528-8307-4f8e-862d-27b9a71d64a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('save_model_parameters/training_schedule_{}.pickle'.format(tr_schedule), 'rb') as f:\n",
    "        THETA = pickle.load(f)\n",
    "highest_posterior_samples=np.concatenate(\n",
    "    [THETA['highest posterior samples'][cell] if cell in THETA['highest posterior samples'] else np.ones((13,))*np.nan for cell in Xo.index]\n",
    ").reshape((Xo.shape[0],len(model_param_names)))\n",
    "posterior_samples_10_random=np.concatenate(\n",
    "    [THETA['10 random samples'][cell].numpy() if cell in THETA['10 random samples'] else np.ones((10,13))*np.nan for cell in Xo.index]\n",
    ").reshape((Xo.shape[0]*10,len(model_param_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceaab61-abce-4919-8c49-8ff7c2b38cb8",
   "metadata": {},
   "source": [
    "#### Let's get their summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f12fe92-ce1c-4b5f-a356-64e9328aded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulator import EphysModel\n",
    "\n",
    "M1_model=EphysModel(name='M1',\n",
    "                   T=25.0,\n",
    "                   E_Na=69.0,\n",
    "                   E_K=-98.4,\n",
    "                   E_Ca=127.2,\n",
    "                   start=100,\n",
    "                   end=700,\n",
    "                   dt=0.04,\n",
    "                   label_params=model_param_names,\n",
    "                   ephys_features=ephys_features[:-4],\n",
    "                   n_processes=40,\n",
    "                   noise_factor=10,\n",
    "                   use_pathos=True,\n",
    "                   chunk_size=10000,\n",
    "                   save_chunks=True,\n",
    "                   verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf36e636-9418-4eac-a959-48138bb7b17a",
   "metadata": {},
   "source": [
    "You don't have to run the following 2 blocks again, the summary statistics of all highest posterior samples came with the Github repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "744c6a0d-327f-4777-a24a-519f640686c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest posterior sample simulations done.\n"
     ]
    }
   ],
   "source": [
    "M1_model.sim(torch.as_tensor(highest_posterior_samples, dtype=torch.float32))\n",
    "np.savez('./save_sims/highest_posterior_samples_summ_stats_{}.npz'.format(tr_schedule),\n",
    "     stats=M1_model.stats.numpy()\n",
    "    )\n",
    "print('Highest posterior sample simulations done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bede196-5b22-4280-ba7b-80d4f9c0153c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 random posterior sample simulations done.\n"
     ]
    }
   ],
   "source": [
    "M1_model.sim(torch.as_tensor(posterior_samples_10_random, dtype=torch.float32))\n",
    "np.savez('./save_sims/posterior_samples_10_random_summ_stats_{}.npz'.format(tr_schedule),\n",
    "     stats=M1_model.stats.numpy()\n",
    "    )\n",
    "print('10 random posterior sample simulations done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "914e20fe-e3e4-4a89-8b69-185db1cb9300",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_post_stats=np.load('./save_sims/highest_posterior_samples_summ_stats_{}.npz'.format(tr_schedule))['stats']\n",
    "highest_post_stats_nans=np.isnan(highest_post_stats.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57cf9f7c-fb53-42f2-b601-362eb20181b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfomance for amortized posterior in training schedule 2d regarding drawing highest posterior samples: \n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "24 out of 955 failed or 2.51 %. \n",
      "On simulations that were succesful we are 4.35 +/- 2.86 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n"
     ]
    }
   ],
   "source": [
    "print('Perfomance for amortized posterior in training schedule {} regarding drawing highest posterior samples: '.format(tr_schedule))\n",
    "print('---------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "score=np.mean(\n",
    "    np.sqrt(\n",
    "        np.sum(\n",
    "            (\n",
    "                (highest_post_stats[~highest_post_stats_nans]-Xo_mean)/Xo_std-\\\n",
    "                (Xo[~highest_post_stats_nans]-Xo_mean)/Xo_std\n",
    "            )**2,axis=1\n",
    "        )\n",
    "    )\n",
    ")\n",
    "score_sd=np.std(\n",
    "    np.sqrt(\n",
    "        np.sum(\n",
    "            (\n",
    "                (highest_post_stats[~highest_post_stats_nans]-Xo_mean)/Xo_std-\\\n",
    "                (Xo[~highest_post_stats_nans]-Xo_mean)/Xo_std\n",
    "            )**2,axis=1\n",
    "        )\n",
    "    )\n",
    ")\n",
    "print(sum(highest_post_stats_nans), 'out of', Xo.shape[0],\n",
    "      'failed or {:.2f} %.'.format(sum(highest_post_stats_nans)/(Xo.shape[0])*100),\n",
    "      '\\nOn simulations that were succesful we are {:.2f} +/- {:.2f} (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.'.format(score, score_sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd8a1de-c89d-4f97-ae09-a151983c692b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W.r.t. the prior: \n",
      "----------------- \n",
      "0 out of 955 failed or 0.00 %. \n",
      "On simulations that were succesful we are 2.63 +/- 0.81 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n"
     ]
    }
   ],
   "source": [
    "best_prior_stats=np.load('./save_sims/best_1000_Euclidean_sims.npz')['stats'][::1000,:]\n",
    "best_prior_stats_nans=np.isnan(best_prior_stats.sum(axis=1))\n",
    "Xo_values=Xo.values\n",
    "print('W.r.t. the prior: ')\n",
    "print('----------------- ')\n",
    "score=np.mean(\n",
    "    np.sqrt(\n",
    "        np.sum(\n",
    "            (\n",
    "                (best_prior_stats[~best_prior_stats_nans,:]-Xo_mean)/Xo_std-\\\n",
    "                (Xo_values[~best_prior_stats_nans,:]-Xo_mean)/Xo_std\n",
    "            )**2,axis=1\n",
    "        )\n",
    "    )\n",
    ")\n",
    "score_sd=np.std(\n",
    "    np.sqrt(\n",
    "        np.sum(\n",
    "            (\n",
    "                (best_prior_stats[~best_prior_stats_nans,:]-Xo_mean)/Xo_std-\\\n",
    "                (Xo_values[~best_prior_stats_nans,:]-Xo_mean)/Xo_std\n",
    "            )**2,axis=1\n",
    "        )\n",
    "    )\n",
    ")\n",
    "print(sum(best_prior_stats_nans), 'out of', Xo.shape[0],\n",
    "      'failed or {:.2f} %.'.format(sum(best_prior_stats_nans)/(Xo.shape[0])*100),\n",
    "      '\\nOn simulations that were succesful we are {:.2f} +/- {:.2f} (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.'.format(score, score_sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cc3aac8-07b2-4fe3-b877-9255de8cdfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_samples_10_random_stats=np.load('./save_sims/posterior_samples_10_random_summ_stats_{}.npz'.format(tr_schedule))['stats']\n",
    "post_samples_10_random_stats_nans=np.isnan(post_samples_10_random_stats.mean(axis=1))\n",
    "Xo_repeated=np.repeat(Xo.values, 10, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20656284-356f-4232-9608-10ca422e5b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfomance for amortized posterior in training schedule 2d regarding drawing 10 random posterior samples: \n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "594 out of 9550 failed or 6.22 %. \n",
      "On simulations that were succesful we are 5.11 +/- 3.03 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n"
     ]
    }
   ],
   "source": [
    "print('Perfomance for amortized posterior in training schedule {} regarding drawing 10 random posterior samples: '.format(tr_schedule))\n",
    "print('-----------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "#for i, tr_schedule in enumerate(training_schedules):\n",
    "score=np.mean(\n",
    "    np.sqrt(\n",
    "        np.sum(\n",
    "            (\n",
    "                (post_samples_10_random_stats[~post_samples_10_random_stats_nans]-Xo_mean)/Xo_std-\\\n",
    "                (Xo_repeated[~post_samples_10_random_stats_nans]-Xo_mean)/Xo_std\n",
    "            )**2,axis=1\n",
    "        )\n",
    "    )\n",
    ")\n",
    "score_sd=np.std(\n",
    "    np.sqrt(\n",
    "        np.sum(\n",
    "            (\n",
    "                (post_samples_10_random_stats[~post_samples_10_random_stats_nans]-Xo_mean)/Xo_std-\\\n",
    "                (Xo_repeated[~post_samples_10_random_stats_nans]-Xo_mean)/Xo_std\n",
    "            )**2,axis=1\n",
    "        )\n",
    "    )\n",
    ")\n",
    "print(sum(post_samples_10_random_stats_nans), 'out of', Xo.shape[0]*10,\n",
    "      'failed or {:.2f} %.'.format(sum(post_samples_10_random_stats_nans)/(Xo.shape[0]*10)*100),\n",
    "      '\\nOn simulations that were succesful we are {:.2f} +/- {:.2f} (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.'.format(score, score_sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64ef4d93-cbb7-40fd-be91-0983175db17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 1380007936 bytes == 0xe5ea000 @ \n"
     ]
    }
   ],
   "source": [
    "prior_stats=np.load('./save_sims/M1_chunks/full_batch.npz')['stats']\n",
    "prior_10_random_stats=prior_stats[np.random.randint(0,prior_stats.shape[0],Xo.shape[0]*10),:]\n",
    "prior_10_random_stats_nans=np.isnan(prior_10_random_stats.sum(axis=1))\n",
    "Xo_repeated=np.repeat(Xo.values, 10, axis=0)\n",
    "Xo_mean=Xo.values.mean(axis=0)\n",
    "Xo_std=Xo.values.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "919b07bd-c940-4acb-bb3b-51e58b88bfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W.r.t. the prior: \n",
      "----------------- \n",
      "4994 out of 9550 failed or 52.29 %. \n",
      "On simulations that were succesful we are 11.79 +/- 3.31 (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.\n"
     ]
    }
   ],
   "source": [
    "print('W.r.t. the prior: ')\n",
    "print('----------------- ')\n",
    "score=np.mean(\n",
    "    np.sqrt(\n",
    "        np.sum(\n",
    "            (\n",
    "                (prior_10_random_stats[~prior_10_random_stats_nans,:]-Xo_mean)/Xo_std-\\\n",
    "                (Xo_repeated[~prior_10_random_stats_nans,:]-Xo_mean)/Xo_std\n",
    "            )**2,axis=1\n",
    "        )\n",
    "    )\n",
    ")\n",
    "score_sd=np.std(\n",
    "    np.sqrt(\n",
    "        np.sum(\n",
    "            (\n",
    "                (prior_10_random_stats[~prior_10_random_stats_nans,:]-Xo_mean)/Xo_std-\\\n",
    "                (Xo_repeated[~prior_10_random_stats_nans,:]-Xo_mean)/Xo_std\n",
    "            )**2,axis=1\n",
    "        )\n",
    "    )\n",
    ")\n",
    "print(sum(prior_10_random_stats_nans), 'out of', Xo.shape[0]*10,\n",
    "      'failed or {:.2f} %.'.format(sum(prior_10_random_stats_nans)/(Xo.shape[0]*10)*100),\n",
    "      '\\nOn simulations that were succesful we are {:.2f} +/- {:.2f} (mean +/- s.d.) Z-scored Euclidean ephys distance far from the experimental observation.'.format(score, score_sd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d96f6b-8cff-47c8-b275-3ab3b2f2ea2f",
   "metadata": {},
   "source": [
    "We can pick our favourite training schedule and generate more samples with their evaluations. We can use this to evaluate the entropy for instance in `build_figures.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2eaddd1-afa9-4064-b177-4a66d939aea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    /usr/local/lib/python3.8/dist-packages/pkg_resources/__init__.py:122: PkgResourcesDeprecationWarning: 0.23ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      " [py.warnings]\n",
      "WARNING    /usr/local/lib/python3.8/dist-packages/pkg_resources/__init__.py:122: PkgResourcesDeprecationWarning: 0.1.36ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      " [py.warnings]\n"
     ]
    }
   ],
   "source": [
    "fav_tr_schedule='2d'\n",
    "with open('./save_posteriors/training_schedule_{}.pickle'.format(fav_tr_schedule), 'rb') as f:\n",
    "    posterior = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9962642-3462-4137-a096-3377a513697e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "index=0\n",
    "feature_list=range(23)\n",
    "fav_training_schedule={'samples':{}, 'evaluations':{}}\n",
    "for i in range(index, Xo.shape[0]):\n",
    "    xo=Xo.iloc[i,:].values\n",
    "    cell_name=Xo.index[i]\n",
    "    print('.', end='')\n",
    "\n",
    "    # sampling 1000 from the posterior\n",
    "    samples=posterior.sample(\n",
    "        (1000,),\n",
    "        x=torch.as_tensor(xo[feature_list], dtype=float),\n",
    "        show_progress_bars=False\n",
    "    )\n",
    "    evaluations=posterior.log_prob(\n",
    "        samples,\n",
    "        x=torch.as_tensor(xo[feature_list], dtype=float)\n",
    "    )\n",
    "    fav_training_schedule['samples'].update({cell_name:samples.numpy()})\n",
    "    fav_training_schedule['evaluations'].update({cell_name:evaluations.numpy()})\n",
    "    \n",
    "with open('save_model_parameters/favourite_training_schedule.pickle', 'wb') as f:\n",
    "    pickle.dump(fav_training_schedule, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
